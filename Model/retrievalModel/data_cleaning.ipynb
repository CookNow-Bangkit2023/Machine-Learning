{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "raw_recipe_path = \"../../Dataset/RAW_recipes.csv\"\n",
    "df_raw_recipe = pd.read_csv(raw_recipe_path)\n",
    "\n",
    "# Remove Na datas\n",
    "def preprocess_data(df):\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Filtering attribute\n",
    "    df = df[[\"name\", \"id\", \"ingredients\"]]\n",
    "    \n",
    "    # Remove recipes duplicate\n",
    "    df = df.drop_duplicates(subset=[\"name\", \"ingredients\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "df = preprocess_data(df_raw_recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_array_values = df[\"ingredients\"].apply(lambda line : re.findall(r\"\\b[a-z]\\w+\\b\", line)).values\n",
    "ingredients_array    = df[\"ingredients\"].apply(lambda line : re.findall(r\"'(.*?)'\", line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary = nltk.FreqDist()\n",
    "\n",
    "# for ingredients in ingredients_array.values:\n",
    "#     # ingredients = ingredients.split()\n",
    "#     ingredients = ingredient_parse(ingredients)\n",
    "#     vocabulary.update(ingredients)\n",
    "\n",
    "# for word, frequency in vocabulary.most_common():\n",
    "#     print(f'{word} : {frequency}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingredient_parse(ingredients_array):\n",
    "\n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "    words_to_remove = [\n",
    "        ',', ' ', \"&\", 'fresh', 'ground', 'red', 'black', 'green', 'white','and', 'all', 'purpose',\n",
    "        'of', 'dry', 'frozen', 'light', 'skinless', 'yellow', 'half', 'new', 'whole', 'and', 'of', 'clove',\n",
    "        'prepared', \"hard-cooked\", \"extract\", \"semi-sweet\", \"in\", \"fillet\", \"purple\", \"s\", \"hot\", \"yolk\", \"freshly\",\n",
    "        \"table\", \"boiling\", \"warm\", \"cold\"\n",
    "    ]\n",
    "\n",
    "    ordinary = [\n",
    "        \"salt\", \"pepper\", \"water\", \"sugar\", \"salt pepper\", \"seasoning salt\", \"ice water\", \"tap water\"\n",
    "    ]\n",
    "    \n",
    "\n",
    "    ingredient_list = []\n",
    "    for items in ingredients_array:\n",
    "        # print(items)\n",
    "        \n",
    "        # Split by word\n",
    "        items = items.split(\" \")\n",
    "        # Lowercase\n",
    "        items = [word.lower() for word in items]\n",
    "        # Clean symbols\n",
    "        items = [word.strip('\", ') for word in items]\n",
    "        # Lemmatize words so we can compare words to measuring words\n",
    "        items = [lemmatizer.lemmatize(word) for word in items]\n",
    "        # Get rid of common easy words\n",
    "        items = [word for word in items if word not in words_to_remove]\n",
    "\n",
    "        # items = [word for word in items if word not in ordinary]\n",
    "\n",
    "        if items:\n",
    "            items = ' '.join(items)\n",
    "\n",
    "            # Last clean from spaces\n",
    "            items = items.strip(\" \")\n",
    "            \n",
    "            # Remove ordinary ingredients\n",
    "            if not(items in ordinary) and items != \" \":\n",
    "                ingredient_list.append(items)\n",
    "            \n",
    "\n",
    "    return ingredient_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_clean = ingredients_array.apply(ingredient_parse).values\n",
    "labels = df[\"id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['winter squash', 'mexican seasoning', 'mixed spice', 'honey', 'butter', 'olive oil']),\n",
       "       list(['pizza crust', 'sausage patty', 'egg', 'milk', 'cheese']),\n",
       "       list(['beef', 'onion', 'diced tomato', 'tomato paste', 'tomato soup', 'rotel tomato', 'kidney bean', 'chili powder', 'cumin', 'lettuce', 'cheddar cheese']),\n",
       "       ...,\n",
       "       list(['egg', 'mayonnaise', 'dijon mustard', 'salt-free cajun seasoning', 'tabasco sauce', 'italian parsley']),\n",
       "       list(['butter', 'eagle brand condensed milk', 'brown sugar', 'sour cream', 'egg', 'nutmeg', 'self-rising flour', 'bisquick', 'wooden popsicle stick']),\n",
       "       list(['granulated sugar', 'shortening', 'egg', 'flour', 'cream tartar', 'baking soda', 'vanilla'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ingredients to TF-IDF vectors\n",
    "# combined = []\n",
    "# for sublist in ingredients_array_values:\n",
    "#     combined += sublist\n",
    "\n",
    "# combined = ingredients_array_values\n",
    "\n",
    "# vectorizer = TfidfVectorizer()\n",
    "# X = vectorizer.fit_transform(ingredients_array_values)\n",
    "\n",
    "# # Apply K-means clustering\n",
    "# k = 10\n",
    "# kmeans = KMeans(n_clusters=k)\n",
    "# kmeans.fit(X)\n",
    "\n",
    "# # Assign each ingredient to a cluster\n",
    "# ingredient_clusters = kmeans.predict(X)\n",
    "\n",
    "# # Print ingredient clusters\n",
    "# for cluster_id in range(k):\n",
    "#     cluster_ingredients = [ingredient for i, ingredient in enumerate(ingredients) if ingredient_clusters[i] == cluster_id]\n",
    "#     print(f\"Cluster {cluster_id + 1}: {cluster_ingredients}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input():\n",
    "    user_input = input(\"Masukkan bahan-bahan pisah dengan (, ) : \")\n",
    "    return user_input.split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_recipe(user_input):\n",
    "    matched_recipes = []\n",
    "\n",
    "    for ingre, label in zip(ingredients_clean, labels):\n",
    "        if all(i in user_input for i in ingre):\n",
    "            # print(ingre, label)\n",
    "            matched_recipes.append(label)\n",
    "\n",
    "    return matched_recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(i in ingredients_clean[] for i in user_input))\n",
    "# print(user_input)\n",
    "# print(ingredients_clean[107699])\n",
    "# tuple(zip(ingredients_clean, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resep rekomendasi :\n",
      "easy peel boiled eggs, 531398, ['egg', 'water']\n",
      "boiled eggs, 160167, ['eggs', 'water', 'salt']\n",
      "souffle omelet  puffy omelet, 89596, ['egg whites', 'water', 'salt', 'egg yolks', 'butter']\n",
      "calming cedar tea, 352667, ['greens', 'water', 'white sugar']\n",
      "caramelized simple syrup, 179600, ['sugar', 'boiling water']\n",
      "hard boiled eggs  easy to peel, 382101, ['eggs', 'water', 'salt']\n",
      "oeufs au plat, 470634, ['eggs', 'butter', 'salt', 'pepper']\n",
      "easter hard boiled eggs, 354371, ['egg']\n",
      "please ignore, 409347, ['egg', 'water']\n",
      "high altitude hard boiled eggs, 408065, ['eggs', 'water']\n"
     ]
    }
   ],
   "source": [
    "user_input = get_input()\n",
    "reccomendation = filter_recipe(user_input)\n",
    "\n",
    "# Random recipes\n",
    "random.shuffle(reccomendation)\n",
    "\n",
    "if reccomendation:\n",
    "    print(\"Resep rekomendasi :\")\n",
    "    for i in reccomendation[0:10]:\n",
    "        recipe_name = df.loc[df[\"id\"] == int(i)][\"name\"].item()\n",
    "        ingre = df.loc[df[\"id\"] == int(i)][\"ingredients\"].item()\n",
    "        print(f\"{recipe_name}, {i}, {ingre}\")\n",
    "\n",
    "else:\n",
    "    print(\"Resep tidak ditemukan\")\n",
    "    # print(reccomendation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save recipes as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = []\n",
    "\n",
    "# for ingre, label in zip(ingredients_clean, labels):\n",
    "#     temp = {\n",
    "#         \"recipes_id\" : str(label),\n",
    "#         \"ingredients\" : ingre\n",
    "#     }\n",
    "#     res.append(temp)\n",
    "\n",
    "# with open(\"clean_recipes.json\", \"w\") as outfile:\n",
    "#     json.dump(res, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
